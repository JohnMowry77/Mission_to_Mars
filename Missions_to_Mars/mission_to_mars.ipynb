{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from splinter import Browser\n",
    "import requests\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [/Users/johnmowry/.wdm/drivers/chromedriver/mac64/89.0.4389.23/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "#create a driver #Splinter\n",
    "executable_path={'executable_path': ChromeDriverManager().install()}\n",
    "browser=Browser('chrome', **executable_path, headless=False)\n",
    "# sepearte line use browser.visit(url)\n",
    "#headless==False will show you the browser. blank will run in the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another First: Perseverance Captures the Sounds of Driving on Mars\n",
      "NASAâ€™s newest rover recorded audio of itself crunching over the surface of the Red Planet, adding a whole new dimension to Mars exploration.\n"
     ]
    }
   ],
   "source": [
    "# scrape the [NASA Mars News Site] (https://mars.nasa.gov/news/)\n",
    "mars_news_path='https://mars.nasa.gov/news/'\n",
    "\n",
    "#use request to pull html\n",
    "mars_news= requests.get(mars_news_path)#.json #returns a response/ #return json --> dictionary (in python)\n",
    "#html=mars_news.html\n",
    "\n",
    "##below is splinter\n",
    "# executable_path={'executable_path': ChromeDriverManager().install()}\n",
    "# browser=Browser('chrome', **executable_path, headless=False)\n",
    "browser.visit(mars_news_path)\n",
    "mars_html=browser.html\n",
    "\n",
    "#use bs to parse out and collect the latest News Title and Paragraph Text. \n",
    "soup=BeautifulSoup(mars_html,'html.parser') # return a soup object\n",
    "\n",
    "#soup.something(specify the tag and class name) => strings\n",
    "#news_p=soup.find(\"div\", class_=\"article_teaser_body\")\n",
    "#news_title=soup.find_all('a')\n",
    "#news_p\n",
    "#news_title=news_title_div.look_for('a').text\n",
    "news_title=soup.findAll(\"div\", class_=\"content_title\")\n",
    "news_title\n",
    "# news_paragraph_div=soup.look_for(specify the tag and class name)\n",
    "# soup.look_for(specify the tag & class name)\n",
    "\n",
    "#append title results to news_titles empty list.\n",
    "news_titles=[]\n",
    "for title in news_title[1]:\n",
    "    children = list(title.children) \n",
    "    if children:\n",
    "        first = children[0] #children is anchor within div class_='content_title)' #a list so use integer index to access\n",
    "        print(getattr(first, \"text\")  # anchor has text\n",
    "              if hasattr(first, \"text\")\n",
    "                  else first)\n",
    "        news_titles.append((getattr(first, \"text\")  # anchor has text #append to empty list\n",
    "              if hasattr(first, \"text\")\n",
    "                  else first))\n",
    "\n",
    "        \n",
    "# news_paragraph_div=soup.look_for(specify the tag and class name)       \n",
    "# soup.something(specify the tag and class name) => strings\n",
    "mars_news_p=soup.findAll(\"div\", class_=\"article_teaser_body\")\n",
    "\n",
    "#news_p      \n",
    "#append teaser results to news_paragraphs empty list.    \n",
    "news_paragraph=[]\n",
    "for teaser in mars_news_p[:1]: #[:10] #List use index integer to pull values.\n",
    "    teaser=list(teaser.children)    #https://www.w3schools.com/jsref/prop_element_children.asp\n",
    "    if teaser:\n",
    "        first=teaser[0] #teaser zero index\n",
    "        print(getattr(first, \"text\") # anchor has text\n",
    "              if hasattr(first, \"text\")\n",
    "                  else first)\n",
    "        \n",
    "        news_paragraph.append((getattr(first, \"text\")  \n",
    "              if hasattr(first, \"text\")\n",
    "                  else first))\n",
    "        \n",
    "#soup.find_all('a')\n",
    "\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print body of html\n",
    "#print(soup.body.prettyify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(news_title[1:41].children)\n",
    "#news_titles[0]\n",
    "# #python allows us to convert a list to string\n",
    "# news_titles\n",
    "# def listToString(s):\n",
    "#     str1 = \"\"\n",
    "#     #return string\n",
    "#     return (str1.join(news_titles))\n",
    "# print(listToString(news_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_paragraph_div=soup.look_for(specify the tag and class name)       \n",
    "# soup.something(specify the tag and class name) => strings\n",
    "# news_p=soup.findAll(\"div\", class_=\"article_teaser_body\")\n",
    "\n",
    "# #news_p      \n",
    "# #append teaser results to news_paragraphs empty list.    \n",
    "# news_paragraph=[]\n",
    "# for teaser in news_p: #[:10]\n",
    "#     teaser=list(teaser.children)    #https://www.w3schools.com/jsref/prop_element_children.asp\n",
    "#     if teaser:\n",
    "#         first=teaser[0]\n",
    "#         print(getattr(first, \"text\")\n",
    "#               if hasattr(first, \"text\")\n",
    "#                   else first)\n",
    "\n",
    "#         news_paragraph.append((getattr(first, \"text\")  # anchor has text\n",
    "#               if hasattr(first, \"text\")\n",
    "#                   else first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_titles\n",
    "#news_paragraph\n",
    "# a list, use index to pull at , news_paragraph[5]\n",
    "\n",
    "# def listToString(s):\n",
    "#     str1 = \"\"\n",
    "#     #return string\n",
    "#     return (str1.join(news_paragraph))\n",
    "# print(listToString(news_paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url=\"https://www.jpl.nasa.gov/images?search=&category=Mars\"\n",
    "\n",
    "browser.visit(image_url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#click the first element img with class_ BaseImage\n",
    "#find_by_css has a img element we can look for\n",
    "browser.find_by_css('img.BaseImage').first.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://d2pn8kiwq2w21t.cloudfront.net/original_images/jpegPIA23729.jpg'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html=browser.html\n",
    "soup=BeautifulSoup(browser.html, 'html.parser')\n",
    "#image_tag=soup.find('img', class_='BaseImage')\n",
    "#image_tag\n",
    "#for each_image in images:\n",
    "#    print(each_image['src'])\n",
    "featured_image_url=soup.find('a', class_='BaseButton')['href'] #might also be able to use ['src']\n",
    "featured_image_url\n",
    "\n",
    "##QUESTION: \n",
    "#Download JPG (Button), in inspect <a> class_='BaseButton text-contrast-none w...'\n",
    "    \n",
    "#do we have to click on download jpeg? \n",
    "#If so do we have to include the entre string after BaseButton class element?\n",
    "# No the space means we could choose one. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The next 2 cells are above. It's cleaner above. \n",
    "\n",
    "#use splinter to navigate the site:\n",
    "\n",
    "#featured_image_url= 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "##featured_image_url=\"https://www.jpl.nasa.gov/images?search=&category=Mars\"\n",
    "#featured_image_url='https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "##USE ME (row 7 or maybe 12)\n",
    "#https://www.jpl.nasa.gov/images?search=&category=Mars\n",
    "\n",
    "#from class\n",
    "#find the first image & click on it and then go to the download jpg \n",
    "# how to find things using a method (look at doc)\n",
    "# most straight forward way. find by css\n",
    "# element type, \n",
    "\n",
    "# you only do browser.find if you are looking to interact with the webpage otherwsie use beautiful soup\n",
    "### IMPORTANT to pull html tag  use [] notation\n",
    "\n",
    "\n",
    "##browser.visit(featured_image_url)\n",
    "##time.sleep(0.25)\n",
    "\n",
    "#scrap\n",
    "#html=browser.html\n",
    "\n",
    "# save a complete url string to this image\n",
    "#soup=BeautifulSoup(htmlhtml, 'html.parser')\n",
    "#browser.find_by_css('.BaseImage').click()\n",
    "\n",
    "#click the first element img with class_ BaseImage\n",
    "\n",
    "##submit=browser.find_by_css('img.BaseImage').first.click()\n",
    "##time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then grab the html at the new page\n",
    "                    \n",
    "##html=browser.html\n",
    "##soup=BeautifulSoup(browser.html, 'html.parser')\n",
    "\n",
    "#image_tag=soup.find('img', class_='BaseImage')\n",
    "\n",
    "#image_tag\n",
    "#for each_image in images:\n",
    "#    print(each)image['src'])\n",
    "\n",
    "##soup.find('a', class_='BaseButton')['href']\n",
    "\n",
    "#time.sleep(1)\n",
    "\n",
    "#splinter find elemnts: #missing a step?\n",
    "#image_tag=browser.links.find_by_partial_href('image/mars/').click()\n",
    "\n",
    "##FOLLOW UP NEEDED  ###FIND The 'src' use .get ???\n",
    "# #get the href property of the image_tag\n",
    "# image_url=image_tag.get('src')\n",
    "# image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###you need Splinter to be able to click. \n",
    "#the next 5 lines won't allow you to do what it is required. You can't interact withour splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url to be scrapped\n",
    "#featured_image_url=\"https://www.jpl.nasa.gov/images?search=&category=Mars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrive page with the requests module\n",
    "# response=requests.get(featured_image_url)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create BeautifulSoup object; parse w/ 'html.parser'\n",
    "\n",
    "#soup = BeautifulSoup(response.text, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contians Mars Image\n",
    "\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the results\n",
    "# results are returned as an iterable list\n",
    "\n",
    "## find all gives you a list\n",
    "# results = soup.find_all('a', class_='BassButton')\n",
    "\n",
    "# results\n",
    "\n",
    "# # #Loop through returned results:\n",
    "# for result in results:\n",
    "#     try:\n",
    "#         image_url=result.find('a', class_='BassButton')['href']\n",
    "# #         link= result.a['href']\n",
    "        \n",
    "#         if image_url:\n",
    "#             print(image_url)\n",
    "#             print(link)\n",
    "        \n",
    "#     except AttributeError as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# use pandas to scrape the table containing facts about the planent including Diameter, Mass, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://space-facts.com/mars/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                      0                              1\n",
       " 0  Equatorial Diameter:                       6,792 km\n",
       " 1       Polar Diameter:                       6,752 km\n",
       " 2                 Mass:  6.39 Ã— 10^23 kg (0.11 Earths)\n",
       " 3                Moons:            2 (Phobos & Deimos)\n",
       " 4       Orbit Distance:       227,943,824 km (1.38 AU)\n",
       " 5         Orbit Period:           687 days (1.9 years)\n",
       " 6  Surface Temperature:                   -87 to -5 Â°C\n",
       " 7         First Record:              2nd millennium BC\n",
       " 8          Recorded By:           Egyptian astronomers,\n",
       "   Mars - Earth Comparison             Mars            Earth\n",
       " 0               Diameter:         6,779 km        12,742 km\n",
       " 1                   Mass:  6.39 Ã— 10^23 kg  5.97 Ã— 10^24 kg\n",
       " 2                  Moons:                2                1\n",
       " 3      Distance from Sun:   227,943,824 km   149,598,262 km\n",
       " 4         Length of Year:   687 Earth days      365.24 days\n",
       " 5            Temperature:     -87 to -5 Â°C      -88 to 58Â°C,\n",
       "                       0                              1\n",
       " 0  Equatorial Diameter:                       6,792 km\n",
       " 1       Polar Diameter:                       6,752 km\n",
       " 2                 Mass:  6.39 Ã— 10^23 kg (0.11 Earths)\n",
       " 3                Moons:            2 (Phobos & Deimos)\n",
       " 4       Orbit Distance:       227,943,824 km (1.38 AU)\n",
       " 5         Orbit Period:           687 days (1.9 years)\n",
       " 6  Surface Temperature:                   -87 to -5 Â°C\n",
       " 7         First Record:              2nd millennium BC\n",
       " 8          Recorded By:           Egyptian astronomers]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns a list of the table \n",
    "tables = pd.read_html(url)\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can slice dataframes by accessing an index integer value\n",
    "mars_facts=tables[0]\n",
    "#mars_facts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equatorial Diameter:</th>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Polar Diameter:</th>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mass:</th>\n",
       "      <td>6.39 Ã— 10^23 kg (0.11 Earths)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moons:</th>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Distance:</th>\n",
       "      <td>227,943,824 km (1.38 AU)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orbit Period:</th>\n",
       "      <td>687 days (1.9 years)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surface Temperature:</th>\n",
       "      <td>-87 to -5 Â°C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Record:</th>\n",
       "      <td>2nd millennium BC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recorded By:</th>\n",
       "      <td>Egyptian astronomers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Measurement\n",
       "Metric                                             \n",
       "Equatorial Diameter:                       6,792 km\n",
       "Polar Diameter:                            6,752 km\n",
       "Mass:                 6.39 Ã— 10^23 kg (0.11 Earths)\n",
       "Moons:                          2 (Phobos & Deimos)\n",
       "Orbit Distance:            227,943,824 km (1.38 AU)\n",
       "Orbit Period:                  687 days (1.9 years)\n",
       "Surface Temperature:                   -87 to -5 Â°C\n",
       "First Record:                     2nd millennium BC\n",
       "Recorded By:                   Egyptian astronomers"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename columns\n",
    "# should earth be shown?\n",
    "mars_facts=mars_facts.rename(columns=({0: \"Metric\", 1: \"Measurement\"}))\n",
    "#mars_facts\n",
    "\n",
    "mars_facts=mars_facts.set_index('Metric')\n",
    "mars_facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th></th>\n",
      "      <th>Measurement</th>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Metric</th>\n",
      "      <th></th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <th>Equatorial Diameter:</th>\n",
      "      <td>6,792 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Polar Diameter:</th>\n",
      "      <td>6,752 km</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Mass:</th>\n",
      "      <td>6.39 Ã— 10^23 kg (0.11 Earths)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Moons:</th>\n",
      "      <td>2 (Phobos &amp; Deimos)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Distance:</th>\n",
      "      <td>227,943,824 km (1.38 AU)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Orbit Period:</th>\n",
      "      <td>687 days (1.9 years)</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Surface Temperature:</th>\n",
      "      <td>-87 to -5 Â°C</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>First Record:</th>\n",
      "      <td>2nd millennium BC</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <th>Recorded By:</th>\n",
      "      <td>Egyptian astronomers</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "mars_facts=mars_facts.to_html()\n",
    "print(mars_facts)\n",
    "\n",
    "#write html to file\n",
    "text_file= open(\"table.html\", \"w\")\n",
    "text_file.write(mars_facts)\n",
    "text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to html, replace \"\\n\" to get html code\n",
    "# mars_facts=mars_facts.to_html()\n",
    "# mars_facts\n",
    "\n",
    "##### QUESTION: if we drop \\n and convert to space, do we lose attribute 'to_html'?\n",
    "## AttributeError: 'str' object has no attribute 'to_html'\n",
    "#mars_facts_html=mars_facts.replace('\\n', '')\n",
    "#mars_facts_html\n",
    "\n",
    "#mars_facts_one=mars_facts_html.to_html('mars_facts.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Hemisphere Url\n",
    "# mars_hemisphere_url='https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "# browser.visit(mars_hemisphere_url)\n",
    "# time.sleep(1)\n",
    "# #mars_hem= requests.get(mars_hemisphere_path)\n",
    "\n",
    "# # Scrape the page into soup\n",
    "# html=browser.html\n",
    "# soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# # empty list to append results:\n",
    "\n",
    "# hemisphere_name=[]\n",
    "\n",
    "# # Search for the hemisphere names\n",
    "# results=soup.find_all('div',class_='collapsible results')\n",
    "# hemispheres=results[0].find_all('h3')\n",
    "# #results\n",
    "\n",
    "# #get text to empty list:\n",
    "# for name in hemispheres:\n",
    "# #    print(name)\n",
    "#     hemisphere_name.append(name.text)\n",
    "     \n",
    "# thumb_link=[]\n",
    "# #Search for thumbnail links\n",
    "# thumb_results=results[0].find_all('a')#['href']\n",
    "# thumb_results\n",
    "\n",
    "# #find full-size image:\n",
    "# for thumb in thumb_results:\n",
    "#     # if the thumbnail element has an image\n",
    "#     if (thumb.img):\n",
    "#     # then grab the link\n",
    "#         thumb_url='https://astrogeology.usgs.gov/' + thumb['href']\n",
    "    \n",
    "#     # Append list with links\n",
    "#     thumb_link.append(thumb_url)\n",
    "    \n",
    "###### CODE ABOVE GIVES YOU SOMETHING BUT IT ISN\"T CORRECT\n",
    "\n",
    "# full_img=[]\n",
    "# # click each of the links to the hemisphere in order to find the img url to the full resolution img.\n",
    "# for url in thumb_link:\n",
    "#     results=soup.find_all('img', class_='wide-image')\n",
    "#     img_path= results[0]['src'] #results 0 index grab 'src' tag\n",
    "    \n",
    "#     #combine img_path with url, similar to above:\n",
    "#     img_link -'https://astrogeology.usgs.gov/' + img_path\n",
    "#     #append to full_img list\n",
    "#     full_img.append(img_link)\n",
    "\n",
    "# mars_hem_list=[]\n",
    "# #Mongo wants a list so append the list with dict\n",
    "# mars_hem_dict={}\n",
    "# #you should have the hemisphere names & image links\n",
    "# # need to combine these to put into dict?\n",
    "# mars_hem_dict['name']=title\n",
    "# mars_hem_dict['full_img']=img\n",
    "\n",
    "# mars_hem_list.append(mars_hem_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hemisphere_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hemisphere_name=[]\n",
    "# thumb_link=[]\n",
    "# full_img=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Hemisphere Url\n",
    "mars_hemisphere_url='https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "# Scrape the page into soup\n",
    "browser.visit(mars_hemisphere_url)\n",
    "html=browser.html\n",
    "soup=BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "hemisphere=browser.find_by_css('.thumb').click()\n",
    "#print(hemisphere)\n",
    "#image=soup.findAll('img')\n",
    "#image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cerberus Hemisphere Enhanced\n",
      "/search/map/Mars/Viking/cerberus_enhanced\n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif\n",
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}]\n",
      "------------\n",
      "Cerberus Hemisphere Enhanced\n",
      "/search/map/Mars/Viking/schiaparelli_enhanced\n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif\n",
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}, {'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}]\n",
      "------------\n",
      "Cerberus Hemisphere Enhanced\n",
      "/search/map/Mars/Viking/syrtis_major_enhanced\n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif\n",
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}, {'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}, {'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}]\n",
      "------------\n",
      "Cerberus Hemisphere Enhanced\n",
      "/search/map/Mars/Viking/valles_marineris_enhanced\n",
      "https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif\n",
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}, {'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}, {'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}, {'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}]\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# Scrape Hemisphere Url\n",
    "\n",
    "#mars_hemisphere_path='https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "#mars_hem= requests.get(mars_hemisphere_path)\n",
    "\n",
    "#https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\n",
    "mars_hemisphere_url='https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "browser.visit(mars_hemisphere_url)\n",
    "#time.sleep(1)\n",
    "#mars_hem= requests.get(mars_hemisphere_path)\n",
    "\n",
    "#print(soup.prettyify())\n",
    "#hemisphere=browser.find_by_css('.thumb')#.click() \n",
    "\n",
    "###IMPORTANT###  (period). in front for class & # for id in css \n",
    "# Scrape the page into soup\n",
    "html=browser.html\n",
    "soup=BeautifulSoup(html, 'html.parser')\n",
    "#print(soup)\n",
    "\n",
    "# search for the hemisphere names\n",
    "#class_description=browser.find_by_css('.thumb')#.click()\n",
    "mars_hem_photos=soup.find_all('div', class_='description')\n",
    "#mars_hem_photos\n",
    "base_url='https://astrogeology.usgs.gov'\n",
    "\n",
    "#create empty list to append results\n",
    "title_hem=[]\n",
    "links=[]\n",
    "hemisphere_img_urls=[]\n",
    "#use splinter to find by css \n",
    "class_description=browser.find_by_css(\"h3\")\n",
    "\n",
    "#iterate throught list: append title and href\n",
    "#append hem_img_urls\n",
    "for mars_hem in mars_hem_photos:\n",
    "    class_description=browser.find_by_css(\"h3\")\n",
    "    title=class_description.text\n",
    "    print(title)\n",
    "    title_hem.append(title)\n",
    "    link= mars_hem.find('a')\n",
    "#    print(class_description)\n",
    "    #print(link)\n",
    "    href=link['href']\n",
    "    print(href)\n",
    "    links.append(href)\n",
    "    \n",
    "#     browser.find_by_name('send').first.click()\n",
    "#     browser.find_link_by_text('href').first.click()\n",
    "# use splinter to find href, find_by_tag then click\n",
    "    browser.links.find_by_partial_href(href)\n",
    "    browser.find_by_tag('h3').click()\n",
    "    #watch screen\n",
    "    time.sleep(0.5)\n",
    "    #rerun browser\n",
    "    html=browser.html\n",
    "    soup_2=BeautifulSoup(html, 'html.parser')\n",
    "    mars_img_url=browser.find_by_text('Original')['href']\n",
    "    #mars_img_url=soup.find('li')['href']\n",
    "    print(mars_img_url)\n",
    "    hemisphere_dict={\n",
    "    \"title\": title,\n",
    "    \"img_url\": mars_img_url}\n",
    "    hemisphere_img_urls.append(hemisphere_dict)\n",
    "    print(hemisphere_img_urls)\n",
    "    browser.back()\n",
    "    \n",
    "    print(\"------------\")\n",
    "\n",
    "# Stu_Splinter_Day_2_08\n",
    "#         h3 = article.find('h3') #('h3') is a tag\n",
    "#         link = h3.find('a')\n",
    "#         href = link['href'] #['href'] is an attribute\n",
    "#         title = link['title']\n",
    "#         print('-----------')\n",
    "#         print(title)\n",
    "#         print('http://books.toscrape.com/' + href)\n",
    "\n",
    "# #python dict: key value pairs:\n",
    "# # Example:\n",
    "# hemisphere_image_urls = [\n",
    "#     {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "#     {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "# ]\n",
    "\n",
    "#use python dict to store the data using the keys 'img_url' & 'title'\n",
    "# append the dict w/ the img url string & the hemisphere title to a list.\n",
    "# this list will contain one dict for each hemisphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaner above\n",
    "#a_tag=soup.find(\"a\", class_=\"itemLink\")#[\"href\"].click()\n",
    "#time.sleep(1)\n",
    "#print(a_tag)\n",
    "\n",
    "# url_string= soup.find #.click()\n",
    "# # time.sleep(1)\n",
    "# # #url_string = browser.links.find_by_partial_text('')\n",
    "# # url_string=soup.find_all(\"img\", class_='wide-image')#[\"src\"]\n",
    "# url_string\n",
    "\n",
    "# urls=[]\n",
    "\n",
    "# links = soup.find_all('div', {'class': 'image'})\n",
    "# print [i.find('img')['src'] for i in links]\n",
    "# print [i.find('img')['title'] for i in links]\n",
    "\n",
    "\n",
    "# #thumb_url='https://astrogeology.usgs.gov/' + thumb['href']\n",
    "# # obtain high resolution img for each of Mar's hemispheres\n",
    "# # click each of the links to the hemisphere in order to find the img url to the full resolution img.\n",
    "\n",
    "# for i in hemisphere:\n",
    "#     i.click()  #click on the main link to go to wide-image page\n",
    "#     print(hemisphere)\n",
    "#     links=soup.find_all('img', {'class': 'wide-image'})\n",
    "#     print[i.find('img')['src'] for i in links]\n",
    "# #     url_string=soup.find(\"img\", class_='wide-image')#[\"src\"]\n",
    "# #     print('https://astrogeology.usgs.gov/' + url_string)\n",
    "# #     urls.append(url_string)\n",
    "#     browser.back()\n",
    "\n",
    "#wide_img=browser.find_by_css('img.wide-image').click()\n",
    "#time.sleep(1)\n",
    "\n",
    "# wide_img=soup.find_all('img', class_='wide-image')\n",
    "# wide_img_path= wide_img[0]['src'] #results 0 index grab 'src' tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertOneResult at 0x7ffbacf7a4c0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the hemisphere image urls to db.mars_info\n",
    "# make sure you use the correct database in mongo\n",
    "\n",
    "mongo_conn=pymongo.MongoClient('mongodb://localhost:27017')\n",
    "\n",
    "# # Declare the database\n",
    "mars_db_one = mongo_conn[\"mars_db_one\"] #mydb = myclient[\"mydatabase\"]\n",
    "# Declare the collection\n",
    "mars_info = mars_db_one[\"mars\"] #mycol = mydb[\"customers\"]\n",
    "\n",
    "# mars_dict=({'news_titles': news_title, \n",
    "#                           'news_p': news_paragraph,\n",
    "#                             'image_tag': featured_image_url,\n",
    "#                           'mars_facts': mars_facts_html,\n",
    "#                            })\n",
    "\n",
    "###NEWS TITLE NEEDS TO BE A LIST? Row 8 above\n",
    "mars_dict=({ 'news_titles': news_titles, \n",
    "            'news_p': news_paragraph,\n",
    "            'image_tag': featured_image_url,\n",
    "            'mars_facts': \"table_html\",\n",
    "          'hemispheres': hemisphere_img_urls})\n",
    "\n",
    "\n",
    "\n",
    "mars_db_one.mars_info.insert_one(mars_dict)\n",
    "\n",
    "#import pymongo\n",
    "\n",
    "# #myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "# mydb = myclient[\"mydatabase\"]\n",
    "# mycol = mydb[\"customers\"]\n",
    "\n",
    "# mydict = { \"name\": \"John\", \"address\": \"Highway 37\" }\n",
    "\n",
    "# x = mycol.insert_one(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
